{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filepath: str) -> dict:\n",
    "    \"\"\"Read json from file.\"\"\"\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def extract_filename(string: str) -> str:\n",
    "    \"\"\"Return filename in titlecase.\"\"\"\n",
    "    pattern = r'\\/([^\\/]+)\\.json$'\n",
    "    match = re.search(pattern, string)\n",
    "    if match:\n",
    "        file_name = match.group(1)\n",
    "        return file_name.replace('-', ' ').title()\n",
    "    \n",
    "def load_dfs(dir_path: str, category: str) -> DataFrame:\n",
    "    \"\"\"Return list of dataframes.\"\"\"\n",
    "    dataframes = []\n",
    "    files = glob.glob(dir_path)\n",
    "\n",
    "    for file in files:\n",
    "        data = read_json(file)\n",
    "        df = pd.json_normalize(data['data']['rolesByAliases'])  # Break down nested dictionary.\n",
    "        df[category] = extract_filename(file)\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    return pd.concat(dataframes)\n",
    "\n",
    "def create_surrogate_keys(sk_map: dict, df: DataFrame):\n",
    "    \"\"\"\"\"\"\n",
    "    for col, sk in sk_map.items():\n",
    "        df[sk] = pd.factorize(df[col])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3286, 30)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataframes.\n",
    "industries = load_dfs(dir_path='../data/industries/*.json', category='industry')\n",
    "themes = load_dfs(dir_path='../data/themes/*.json', category='theme')\n",
    "\n",
    "# Create master df.\n",
    "df = pd.concat([industries, themes])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused columns\n",
    "df.drop(columns=['roleReviewStatistics', 'growth', 'salarySuggestion'],\n",
    "        inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "col_names = {\n",
    "    'specReqs': 'skill',\n",
    "    'roleReviewStatistics.total': 'totalReviews',\n",
    "    'roleReviewStatistics.remuneration': 'remuneration',\n",
    "    'roleReviewStatistics.employability': 'employability',\n",
    "    'roleReviewStatistics.jobSatisfaction': 'jobSatisfaction',\n",
    "    'roleReviewStatistics.workLifeBalance': 'workLifeBalance',\n",
    "    'roleReviewStatistics.diversityInTasks': 'diversityInTasks',\n",
    "    'roleReviewStatistics.careerProgressionOpportunities': 'careerProgressionOpportunities',\n",
    "    'roleReviewStatistics.overtime.never': 'overtime.never',\n",
    "    'roleReviewStatistics.overtime.often': 'overtime.often',\n",
    "    'roleReviewStatistics.overtime.sometimes': 'overtime.sometimes',\n",
    "    'roleReviewStatistics.weekends.never': 'weekends.never',\n",
    "    'roleReviewStatistics.weekends.often': 'weekends.often',\n",
    "    'roleReviewStatistics.weekends.sometimes': 'weekends.sometimes',\n",
    "    'roleReviewStatistics.shiftWork.never': 'shiftWork.never',\n",
    "    'roleReviewStatistics.shiftWork.often': 'shiftWork.often',\n",
    "    'roleReviewStatistics.shiftWork.sometimes': 'shiftWork.sometimes',\n",
    "    'roleReviewStatistics.lateNights.never': 'lateNights.never',\n",
    "    'roleReviewStatistics.lateNights.often': 'lateNights.often',\n",
    "    'roleReviewStatistics.lateNights.sometimes': 'lateNights.sometimes',\n",
    "    'roleReviewStatistics.workingHoursCount': 'workingHoursCount',\n",
    "    'growth.value': 'growth',\n",
    "    'salarySuggestion.salary_median': 'medianSalary',\n",
    "}\n",
    "\n",
    "df.rename(columns=col_names, inplace=True)\n",
    "\n",
    "# Update dtypes\n",
    "cols = ['remuneration', 'employability', 'jobSatisfaction',\n",
    "        'workLifeBalance', 'diversityInTasks', 'careerProgressionOpportunities']\n",
    "\n",
    "df = df.astype({col: float for col in cols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down skills column.\n",
    "df = df.explode('skill')\n",
    "# Parse the json structure to get the skill.\n",
    "df['skill'] = df['skill'].apply(lambda x: x.get('label') if x is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create surrogate (primary) keys\n",
    "keys = {\n",
    "    'theme': 'themeId',\n",
    "    'industry': 'industryId',\n",
    "    'id': 'jobId',\n",
    "    'skill': 'skillId'\n",
    "}\n",
    "\n",
    "create_surrogate_keys(sk_map=keys, df=df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Themes\n",
    "themes = df[['themeId', 'theme']]\n",
    "themes.dropna(inplace=True)\n",
    "themes.drop_duplicates(inplace=True)\n",
    "themes.set_index('themeId', inplace=True)\n",
    "\n",
    "# Industries\n",
    "industries = df[['industryId', 'industry']]\n",
    "industries.dropna(inplace=True)\n",
    "industries.drop_duplicates(inplace=True)\n",
    "industries.set_index('industryId', inplace=True)\n",
    "\n",
    "# Jobs\n",
    "jobs = df.drop(columns=['industry', 'industryId', 'theme', 'themeId', 'skill', 'skillId'])\n",
    "jobs.drop_duplicates(inplace=True)\n",
    "jobs.set_index('jobId', inplace=True)\n",
    "\n",
    "# Skills\n",
    "skills = df[['skillId', 'skill']]\n",
    "skills.dropna(inplace=True)\n",
    "skills.drop_duplicates(inplace=True)\n",
    "skills.set_index('skillId', inplace=True)\n",
    "\n",
    "# JobsThemes\n",
    "jobs_themes = df[['jobId', 'themeId']]\n",
    "jobs_themes = jobs_themes[jobs_themes['themeId'] > 0]\n",
    "jobs_themes.drop_duplicates(inplace=True)\n",
    "\n",
    "# JobsIndustries\n",
    "jobs_industries = df[['jobId', 'industryId']]\n",
    "jobs_industries = jobs_industries[jobs_industries['industryId'] > 0]\n",
    "jobs_industries.drop_duplicates(inplace=True)\n",
    "\n",
    "# JobsSkills\n",
    "jobs_skills = df[['jobId', 'skillId']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load\n",
    "\n",
    "Load dataframes into sqlite3 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect('seek.db')\n",
    "\n",
    "jobs.to_sql('Jobs', connection, index=True, if_exists='replace')\n",
    "industries.to_sql('Industries', connection, index=True, if_exists='replace')\n",
    "themes.to_sql('Themes', connection, index=True, if_exists='replace')\n",
    "skills.to_sql('Skills', connection, index=True, if_exists='replace')\n",
    "\n",
    "jobs_industries.to_sql('JobsIndustries', connection, index=False, if_exists='replace')\n",
    "jobs_themes.to_sql('JobsThemes', connection, index=False, if_exists='replace')\n",
    "jobs_skills.to_sql('JobsSkills', connection, index=False, if_exists='replace')\n",
    "\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
